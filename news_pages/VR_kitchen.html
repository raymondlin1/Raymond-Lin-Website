<!DOCTYPE html>

<html lang="en-US">

<head>
	<link rel="Stylesheet" href="../styles.css">
	<link rel="icon" href="https://raymondlin1.github.io/Raymond-Lin-Website/logo.ico">
	<title>VR Kitchen</title>
</head>

<body background="https://i.imgur.com/V1ENHhT.jpg">
	<div class="text" id="overlay" style="background-color:rgba(0, 0, 0, 0.75);">
		<div class="nav_bar">
			<a class="text" href="https://raymondlin1.github.io/Raymond-Lin-Website/">Home</a>
			<a class="text" href="https://raymondlin1.github.io/Raymond-Lin-Website/about">About</a>
			<a class="text" href="https://raymondlin1.github.io/Raymond-Lin-Website/projects">Projects</a>
			<a class="text" href="https://raymondlin1.github.io/Raymond-Lin-Website/fitness">Fitness</a>
			<a class="text" href="https://raymondlin1.github.io/Raymond-Lin-Website/tech">Tech</a>
			<a class="text" href="https://raymondlin1.github.io/Raymond-Lin-Website/contact">Contact</a>
		</div>

		<div class="wrapper">
			<h1>Research Paper: VRKitchen - An Interactive 3D Virtual Environment for Task-oriented Learning</h1>

			<hr>

			<div>
				<table>
					<tr>
						<td style="float: right">28th March, 2019</td>
					</tr>
					<tr>
						<td>Hey all! So I finally got around to reading research papers! Here's a cool one I found, that was written by Xiaofeng Gao, Ran Gong, Tianmin Shu, Xu Xie, Shu Wang, and Song-Chun Zhu, at the Center for Vision, Cognition, Learning and Autonomy Lab at UCLA. </td>
					</tr>
				</table>
			</div>

			<hr>

			<table style="table-layout: fixed; width: 100%">
				<tr>
					<td>
						<button style="background: transparent; border: none; float: left;" onclick="enlarge_image('modal_VR_kitchen', 'VR_kitchen', 'modal_VR_kitchen_image', 0)">
							<img class="image" id="VR_kitchen" src="https://raymondlin1.github.io/Raymond-Lin-Website/pics_and_vids/VR_kitchen.PNG" style="width: 500px;">
						</button>
						<div class="modal" id="modal_VR_kitchen">
							<span class="close">&times;</span>
							<img class="modal-content" id="modal_VR_kitchen_image">
						</div>
					</td>
					<td>
						This article discusses the need for AI agents to behave like a human by being able to complete a complex task set, instead of being extremely proficient at a single task. The article states that there are three main problems that agents must solve in order to be able to complete the complex task set. The first is learning the visual representation of a dynamic environment. Some objects in the real world may change their appearance drastically, but AI agents must be able to detect that it is the same item. Second, the AI agent must be able to generate long-term plans for complex tasks. Lastly, the AI agent must be able to learn from a human's demonstration and be able to replicate the task at hand. The experiment was conducted in a virtual kitchen environment, VR Kitchen, made using the Unreal Engine, typically used for games. Then, humans could control the AI agent manually, using an Occulus Rift, or through procedure calls from a Python API. The agents were assigned certain long-term tasks, such as making a sandwich, which requires multiple steps. Some of these steps include gathering ingredients from the fridge, peeling or cutting vegetables, pouring liquids into a container etc... The complex part of this experiment includes the atmocity of steps and the variations in states of some objects. For example, vegetables have different states: unpeeled, peeled, uncut, cut, uncooked, cooked etc... In short, the project revolved around creating a virtual reality system, VRKitchen, which offeres an environment for training and testing AI agents.
					</td>
				</tr>
			</table>

			<hr>

			<div>
				Zhu, Song-Chun, et al. VRKitchen: an Interactive 3D Virtual Environment for Task-Oriented Learning. 13 Mar. 2019, 
				<a href="https://sites.google.com/view/vr-kitchen/">https://sites.google.com/view/vr-kitchen/</a>
				.
			</div>
		</div>
	</div>

	<script src="../scripts.js"></script>
</body>
</html> 